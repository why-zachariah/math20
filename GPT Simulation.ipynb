{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f69cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d152134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import time\n",
    "\n",
    "#initialize the local language model\n",
    "generator = pipeline('text-generation', model='EleutherAI/gpt-neo-1.3B')\n",
    "\n",
    "def get_response_time(prompt):\n",
    "    start_time = time.time()\n",
    "    response = generator(prompt, max_length=30)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "num_samples = 100\n",
    "response_times = []\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    response_time = get_response_time(\"Tell me a fun fact!\")\n",
    "    response_times.append(response_time)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f1df08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response_times' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Convert to numpy array for analysis\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m response_times \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(response_times)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Calculate the sample mean\u001b[39;00m\n\u001b[1;32m      9\u001b[0m sample_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(response_times)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response_times' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#convert to numpy array for analysis\n",
    "response_times = np.array(response_times)\n",
    "\n",
    "#stats calculations\n",
    "\n",
    "#sample mean\n",
    "sample_mean = np.mean(response_times)\n",
    "print(f\"Sample Mean: {sample_mean}\")\n",
    "\n",
    "#variance\n",
    "variance = np.var(response_times, ddof=1)  # Using ddof=1 for sample variance\n",
    "print(f\"Variance: {variance}\")\n",
    "\n",
    "#estimate lambda for exponential distribution\n",
    "lambda_estimate = 1 / np.mean(response_times)\n",
    "\n",
    "#compute variance of respnose times\n",
    "variance_estimate = np.var(response_times)\n",
    "\n",
    "#Kolmogorov-Smirnov test (goodness of fit)\n",
    "d, p_value = stats.kstest(response_times, 'expon', args=(0, 1/lambda_estimate))\n",
    "\n",
    "#output results\n",
    "print(f\"Estimated Lambda: {lambda_estimate}\")\n",
    "print(f\"Variance of Response Times: {variance_estimate}\")\n",
    "print(f\"KS Test Statistic: {d}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "#LLN (law of large numbers!) Observing mean convergence\n",
    "mean_convergence = [np.mean(response_times[:i+1]) for i in range(num_samples)]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_samples + 1), mean_convergence, label='Sample Mean')\n",
    "plt.axhline(y=1/lambda_estimate, color='r', linestyle='--', label=f'Theoretical Mean (1/lambda)')\n",
    "plt.title('Law of Large Numbers: Sample Mean Convergence')\n",
    "plt.xlabel('Number of Samples')\n",
    "plt.ylabel('Sample Mean')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#CLT (Central Limit Theorem) Distribution of Sample Means\n",
    "bootstrap_samples = 1000\n",
    "bootstrap_means = np.random.choice(response_times, (bootstrap_samples, num_samples), replace=True).mean(axis=1)\n",
    "\n",
    "plt.hist(bootstrap_means, bins=20, density=True, alpha=0.6, color='b')\n",
    "plt.title('Bootstrap Distribution of Response Time Means')\n",
    "plt.xlabel('Mean Response Time (seconds)')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "#histogram and exponential distribution\n",
    "plt.hist(response_times, bins=10, density=True, alpha=0.6, color='g')\n",
    "\n",
    "#estimated exponential distribution\n",
    "x = np.linspace(0, max(response_times), 100)\n",
    "plt.plot(x, lambda_estimate * np.exp(-lambda_estimate * x), 'r-', lw=2)\n",
    "\n",
    "plt.title('Response Time Distribution and Exponential Fit')\n",
    "plt.xlabel('Response Time (seconds)')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
